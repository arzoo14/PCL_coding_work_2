

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>3D Object Recognition based on Correspondence Grouping &mdash; PCL DOCUMENTATION 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: dark blue" >
          

          
            <a href="index.html" class="icon icon-home"> PCL DOCUMENTATION
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Basic Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="walkthrough.html">1. PCL Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_structures.html">2. Getting Started / Basic Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_pcl_pcl_config.html">3. Using PCL in your own project</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_pcl_posix.html">4. Compiling PCL from source on POSIX compliant systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="building_pcl.html">5. Customizing the PCL build process</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_pcl_dependencies_windows.html">6. Building PCL’s dependencies from source on Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_pcl_windows.html">7. Compiling PCL from source on Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_pcl_macosx.html">8. Compiling PCL and its dependencies from MacPorts and source on Mac OS X</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing_homebrew.html">9. Installing on Mac OS X using Homebrew</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_pcl_with_eclipse.html">10. Using PCL with Eclipse</a></li>
<li class="toctree-l1"><a class="reference internal" href="generate_local_doc.html">11. Generate a local documentation for PCL</a></li>
<li class="toctree-l1"><a class="reference internal" href="matrix_transform.html">12. Using a matrix to transform a point cloud</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="adding_custom_ptype.html">1. Adding your own custom <cite>PointT</cite> type</a></li>
<li class="toctree-l1"><a class="reference internal" href="writing_new_classes.html">2. Writing a new PCL class</a></li>
</ul>
<p class="caption"><span class="caption-text">Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="how_features_work.html">1. How 3D Features work in PCL</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PCL DOCUMENTATION</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>3D Object Recognition based on Correspondence Grouping</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/correspondence_grouping.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="d-object-recognition-based-on-correspondence-grouping">
<span id="correspondence-grouping"></span><h1>3D Object Recognition based on Correspondence Grouping<a class="headerlink" href="#d-object-recognition-based-on-correspondence-grouping" title="Permalink to this headline">¶</a></h1>
<p>This tutorial aims at explaining how to perform 3D Object Recognition based on the pcl_recognition module.
Specifically, it explains how to use Correspondence Grouping algorithms in order to cluster the set of point-to-point correspondences obtained after the 3D descriptor matching stage into model instances that are present in the current scene.
For each cluster, representing a possible model instance in the scene, the Correspondence Grouping algorithms also output the transformation matrix identifying the 6DOF pose estimation of that model in the current scene.</p>
</div>
<div class="section" id="the-code">
<h1>The code<a class="headerlink" href="#the-code" title="Permalink to this headline">¶</a></h1>
<p>Before you begin, you should download the PCD dataset used in this tutorial from GitHub (<a class="reference external" href="https://github.com/PointCloudLibrary/pcl/blob/master/test/milk.pcd?raw=true">milk.pcd</a> and
<a class="reference external" href="https://github.com/PointCloudLibrary/pcl/blob/master/test/milk_cartoon_all_small_clorox.pcd?raw=true">milk_cartoon_all_small_clorox.pcd</a>) and put the files in a folder of your convenience.</p>
<p>Also, copy and paste the following code into your editor and save it as <code class="docutils literal notranslate"><span class="pre">correspondence_grouping.cpp</span></code> (or download the source file <code class="xref download docutils literal notranslate"><span class="pre">here</span></code>).</p>
</div>
<div class="section" id="walkthrough">
<h1>Walkthrough<a class="headerlink" href="#walkthrough" title="Permalink to this headline">¶</a></h1>
<p>Now let’s take a look at the various parts of the code to see how it works.</p>
<div class="section" id="helper-functions">
<h2>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<p>Let’s start with a couple of useful functions: the first one prints
on the console a short explanation of the several command line switches
that the program can accept.</p>
<p>The second function does the actual parsing of the command line
arguments in order to set the correct parameters for the execution.</p>
<p>It’s important to say that the only command line parameters <em>required</em> when executing this tutorial are the filenames of the
model and the scene, in this exact order. All other parameters are set
to a default value that will make the tutorial work correctly
with the supplied dataset, although with different models and scene some parameter values might need to be adjusted. You can play around with them to see how they influence the final result.</p>
<p>You can choose between two correspondence clustering algorithms with the command line switch <code class="docutils literal notranslate"><span class="pre">--algorithm</span> <span class="pre">(Hough|GC)</span></code></p>
<blockquote>
<div><ul>
<li><dl>
<dt><strong>Hough (default)</strong></dt><dd><p>This is a clustering algorithm based on a 3D Hough voting scheme described in:</p>
<blockquote>
<div><p><em>F. Tombari and L. Di Stefano:</em> “Object recognition in 3D scenes with occlusions and clutter by Hough voting”, 4th Pacific-Rim Symposium on Image and Video Technology, 2010.</p>
</div></blockquote>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>GC</strong></dt><dd><p>This is a geometric consistency clustering algorithm enforcing simple geometric constraints between pairs of correspondences. It builds on the proposal presented in:</p>
<blockquote>
<div><p><em>H. Chen and B. Bhanu:</em> “3D free-form object recognition in range images using local surface patches”, Pattern Recognition Letters, vol. 28, no. 10, pp. 1252-1262, 2007.</p>
</div></blockquote>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<p>Some other interesting switches are <code class="docutils literal notranslate"><span class="pre">-k</span></code>, <code class="docutils literal notranslate"><span class="pre">-c</span></code> and <code class="docutils literal notranslate"><span class="pre">-r</span></code>:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">-k</span></code> shows the keypoints used to compute the correspondences as a blue overlay into the PCL visualizer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-c</span></code> draws a line connecting each pair of model-scene correspondences that <em>survived</em> the clustering process.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-r</span></code> estimates the spatial resolution for the model point cloud and afterwards considers the radii used as parameters as if they were given in units of cloud resolution; thus achieving some sort of resolution invariance that might be useful when using this tutorial with the same command line and different point clouds.</p></li>
</ul>
</div></blockquote>
<p>The next function performs the spatial resolution computation for a given point cloud averaging the distance between each cloud point and its nearest neighbor.</p>
</div>
<div class="section" id="clustering-pipeline">
<h2>Clustering Pipeline<a class="headerlink" href="#clustering-pipeline" title="Permalink to this headline">¶</a></h2>
<p>The main function, which performs the actual clustering, is quite straightforward. We will take a look at each part of code as they appear in the proposed example.</p>
<p>First, the program parses the command line arguments and
loads the model and scene clouds from disk (using the filenames
supplied by the user).</p>
<p>As a second step, only if resolution invariance flag has been enabled in the command line, the program adjusts the radii that will be used in the next sections by multiplying them for the estimated model cloud resolution.</p>
<p>Next, it computes the normals for each point of both the model and the scene cloud with the  <a href="#id1"><span class="problematic" id="id2">:pcl:`NormalEstimationOMP &lt;pcl::NormalEstimationOMP&gt;`</span></a> estimator, using the 10 nearest neighbors of each point (this parameter seems to be fairly ok for many datasets, not just for the one provided).</p>
<p>Then it downsamples each cloud in order to find a small number
of keypoints, which will then be associated to a 3D descriptor in order to perform keypoint matching and determine point-to-point correspondences. The radii used for the
<a href="#id3"><span class="problematic" id="id4">:pcl:`UniformSampling &lt;pcl::UniformSampling&gt;`</span></a> are either the ones set with the command line switches or the defaults.</p>
<p>The next stage consists in associating a 3D descriptor to each model and scene keypoint. In our tutorial, we compute SHOT descriptors using <a href="#id5"><span class="problematic" id="id6">:pcl:`SHOTEstimationOMP &lt;pcl::SHOTEstimationOMP&gt;`</span></a>.</p>
<p>Now we need to determine point-to-point correspondences between
model descriptors and scene descriptors. To do this, the program uses a <a href="#id7"><span class="problematic" id="id8">:pcl:`KdTreeFLANN &lt;pcl::KdTreeFLANN&gt;`</span></a> whose input cloud has been set to the cloud containing the model descriptors.
For each descriptor associated to a scene keypoint, it efficiently finds the most
similar model descriptor based on the Euclidean distance, and it adds this pair to a <a href="#id9"><span class="problematic" id="id10">:pcl:`Correspondences &lt;pcl::Correspondences&gt;`</span></a> vector (only if the two descriptors are similar enough, i.e. their squared distance is less than a threshold, set to 0.25).</p>
<p>The last stage of the pipeline is the actual clustering of the
previously found correspondences.</p>
<p>The default algorithm is <a href="#id11"><span class="problematic" id="id12">:pcl:`Hough3DGrouping &lt;pcl::Hough3DGrouping&gt;`</span></a>, that is based on an Hough Voting process.
Please note that this algorithm needs to associate a Local Reference Frame (LRF) for each keypoint belonging to the clouds which are passed as arguments!
In this example, we explicitly compute the set of LRFs using the <a href="#id13"><span class="problematic" id="id14">:pcl:`BOARDLocalReferenceFrameEstimation &lt;pcl::BOARDLocalReferenceFrameEstimation&gt;`</span></a> estimator before calling the clustering algorithm.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It’s not necessary to explicitly compute the LRFs before calling the clustering algorithm. If the clouds which are fetched to the clustering algorithm do not have a set of LRFs associated, Hough3DGrouping automatically computes them before performing clustering. In particular, this happens when calling the <code class="docutils literal notranslate"><span class="pre">recognize</span></code> (or <code class="docutils literal notranslate"><span class="pre">cluster</span></code>) method without setting the LRFs: in this case you need to specify the radius of the LRF as an additional parameter for the clustering algorithm (with the <code class="docutils literal notranslate"><span class="pre">setLocalRfSearchRadius</span></code> method).</p>
</div>
<p>Alternatively to Hough3DGrouping, and by means of the appropriate command line switch described before, you might choose to employ the <a href="#id15"><span class="problematic" id="id16">:pcl:`GeometricConsistencyGrouping &lt;pcl::GeometricConsistencyGrouping&gt;`</span></a> algorithm. In this case the LRF computation is not needed so we are simply creating an instance of the algorithm class, passing the right parameters and invoking the <code class="docutils literal notranslate"><span class="pre">recognize</span></code> method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">recognize</span></code> method returns a vector of <code class="docutils literal notranslate"><span class="pre">Eigen::Matrix4f</span></code> representing a transformation (rotation + translation) for each instance of the model found in the scene (obtained via Absolute Orientation) and a <strong>vector</strong> of <a href="#id17"><span class="problematic" id="id18">:pcl:`Correspondences &lt;pcl::Correspondences&gt;`</span></a> (a vector of vectors of <a href="#id19"><span class="problematic" id="id20">:pcl:`Correspondence &lt;pcl::Correspondences&gt;`</span></a>) representing the output of the clustering i.e. each element of this vector is in turn a set of correspondences, representing the correspondences associated to a specific model instance in the scene.</p>
<p>If you <strong>only</strong> need the clustered correspondences because you are planning to use them in a different way, you can use the <code class="docutils literal notranslate"><span class="pre">cluster</span></code> method.</p>
</div>
</div>
<div class="section" id="output-and-visualization">
<h2>Output and Visualization<a class="headerlink" href="#output-and-visualization" title="Permalink to this headline">¶</a></h2>
<p>We are almost at the end of this tutorial. The last few words are related to the part of the program that displays the results on the console and over a PCL Visualizer window.</p>
<p>As a first thing we are showing, for each instance of the model found into the scene, the transformation  matrix and the number of correspondences extracted by the clustering method.</p>
<p>The program then shows in a <a href="#id21"><span class="problematic" id="id22">:pcl:`PCLVisualizer &lt;pcl::visualization::PCLVisualizer&gt;`</span></a> window the scene cloud with a red overlay where an instance of the model has been found.
If the command line switches <code class="docutils literal notranslate"><span class="pre">-k</span></code> and <code class="docutils literal notranslate"><span class="pre">-c</span></code> have been used, the program also shows a “stand-alone” rendering of the model cloud. If keypoint visualization is enabled, keypoints are displayed as blue dots and if correspondence visualization has been enabled they are shown as a green line for each correspondence which <em>survived</em> the clustering process.</p>
</div>
</div>
<div class="section" id="compiling-and-running-the-program">
<h1>Compiling and running the program<a class="headerlink" href="#compiling-and-running-the-program" title="Permalink to this headline">¶</a></h1>
<p>Create a <cite>CMakeLists.txt</cite> file and add the following lines into it:</p>
<p>After you have created the executable, you can then launch it following this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./correspondence_grouping milk.pcd milk_cartoon_all_small_clorox.pcd
</pre></div>
</div>
<p>Or, alternatively, if you prefer specifying the radii in units of cloud resolution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./correspondence_grouping milk.pcd milk_cartoon_all_small_clorox.pcd milk.pcd milk_cartoon_all_small_clorox.pcd -r --model_ss 7.5 --scene_ss 20 --rf_rad 10 --descr_rad 15 --cg_size 10
</pre></div>
</div>
<p>Remember to replace <code class="docutils literal notranslate"><span class="pre">milk.pcd</span></code> and <code class="docutils literal notranslate"><span class="pre">milk_cartoon_all_small_clorox.pcd</span></code> with model and scene filenames, in this exact order. If you want you can add other command line options as described at the beginning of this tutorial.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you are using different point clouds and you don’t know how to set the various parameters for this tutorial you can use the <code class="docutils literal notranslate"><span class="pre">-r</span></code> flag and try setting the LRF and descriptor radii to 5, 10, 15 or 20 times the actual cloud resolution. After that you probably will have to tweak the values by hand to achieve the best results.</p>
</div>
<p>After a few seconds, you will see an output similar to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span> <span class="n">total</span> <span class="n">points</span><span class="p">:</span> <span class="mi">13704</span><span class="p">;</span> <span class="n">Selected</span> <span class="n">Keypoints</span><span class="p">:</span> <span class="mi">732</span>
<span class="n">Scene</span> <span class="n">total</span> <span class="n">points</span><span class="p">:</span> <span class="mi">307200</span><span class="p">;</span> <span class="n">Selected</span> <span class="n">Keypoints</span><span class="p">:</span> <span class="mi">3747</span>

<span class="n">Correspondences</span> <span class="n">found</span><span class="p">:</span> <span class="mi">1768</span>
<span class="n">Model</span> <span class="n">instances</span> <span class="n">found</span><span class="p">:</span> <span class="mi">1</span>

  <span class="n">Instance</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">Correspondences</span> <span class="n">belonging</span> <span class="n">to</span> <span class="n">this</span> <span class="n">instance</span><span class="p">:</span> <span class="mi">24</span>

        <span class="o">|</span>  <span class="mf">0.969</span> <span class="o">-</span><span class="mf">0.120</span>  <span class="mf">0.217</span> <span class="o">|</span>
    <span class="n">R</span> <span class="o">=</span> <span class="o">|</span>  <span class="mf">0.117</span>  <span class="mf">0.993</span>  <span class="mf">0.026</span> <span class="o">|</span>
        <span class="o">|</span> <span class="o">-</span><span class="mf">0.218</span> <span class="o">-</span><span class="mf">0.000</span>  <span class="mf">0.976</span> <span class="o">|</span>

    <span class="n">t</span> <span class="o">=</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.159</span><span class="p">,</span> <span class="mf">0.212</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.042</span> <span class="o">&gt;</span>
</pre></div>
</div>
<p>The output window should look like this (depending on the command line options used):</p>
<a class="reference internal image-reference" href="_images/correspondence_grouping.jpg"><img alt="_images/correspondence_grouping.jpg" src="_images/correspondence_grouping.jpg" style="height: 400px;" /></a>
<a class="reference internal image-reference" href="_images/correspondence_grouping_k.jpg"><img alt="_images/correspondence_grouping_k.jpg" src="_images/correspondence_grouping_k.jpg" style="height: 400px;" /></a>
<a class="reference internal image-reference" href="_images/correspondence_grouping_c.jpg"><img alt="_images/correspondence_grouping_c.jpg" src="_images/correspondence_grouping_c.jpg" style="height: 400px;" /></a>
<a class="reference internal image-reference" href="_images/correspondence_grouping_k_c.jpg"><img alt="_images/correspondence_grouping_k_c.jpg" src="_images/correspondence_grouping_k_c.jpg" style="height: 400px;" /></a>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Arzoo

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-XXXXXXX-1', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>